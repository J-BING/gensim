{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim `Doc2Vec` Tutorial on the IMDB Sentiment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this tutorial, we will learn how to apply Doc2vec using gensim by recreating the results of <a href=\"https://arxiv.org/pdf/1405.4053.pdf\">Le and Mikolov 2014</a>. \n",
    "\n",
    "### Bag-of-words Model\n",
    "Early state-of-the-art document representations were based on the <a href=\"https://en.wikipedia.org/wiki/Bag-of-words_model\">bag-of-words model</a>, which represent input documents as a fixed-length vector. For example, borrowing from the Wikipedia article, the two documents  \n",
    "(1) `John likes to watch movies. Mary likes movies too.`  \n",
    "(2) `John also likes to watch football games.`  \n",
    "are used to construct a length 10 list of words  \n",
    "`[\"John\", \"likes\", \"to\", \"watch\", \"movies\", \"Mary\", \"too\", \"also\", \"football\", \"games\"]`  \n",
    "so then we can represent the two documents as fixed length vectors whose elements are the frequencies of the corresponding words in our list  \n",
    "(1) `[1, 2, 1, 1, 2, 1, 1, 0, 0, 0]`  \n",
    "(2) `[1, 1, 1, 1, 0, 0, 0, 1, 1, 1]`  \n",
    "Bag-of-words models are surprisingly effective but still lose information about word order. Bag of <a href=\"https://en.wikipedia.org/wiki/N-gram\">n-grams</a> models consider word phrases of length n to represent documents as fixed-length vectors to capture local word order but suffer from data sparsity and high dimensionality.\n",
    "\n",
    "### `Word2Vec`\n",
    "`Word2Vec` is a more recent model that embeds words in a lower-dimensional vector space using a shallow neural network. The result is a set of word-vectors where vectors close together in vector space have similar meanings based on context, and word-vectors distant to each other have differing meanings. For example, `strong` and `powerful` would be close together and `strong` and `Paris` would be relatively far. There are two versions of this model based on skip-grams (SG) and continuous-bag-of-words (CBOW), both implemented by the gensim `Word2Vec` class.\n",
    "\n",
    "\n",
    "#### `Word2Vec` - Skip-gram Model\n",
    "The skip-gram <a href=\"http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/\">word2vec</a> model, for example, takes in pairs (word1, word2) generated by moving a window across text data, and trains a 1-hidden-layer neural network based on the synthetic task of given an input word, giving us a predicted probability distribution of nearby words to the input. A virtual <a href=\"https://en.wikipedia.org/wiki/One-hot\">one-hot</a> encoding of words goes through a 'projection layer' to the hidden layer; these projection weights are later interpreted as the word embeddings. So if the hidden layer has 300 neurons, this network will give us 300-dimensional word embeddings.\n",
    "\n",
    "#### `Word2Vec` - Continuous-bag-of-words Model\n",
    "Continuous-bag-of-words Word2vec is very similar to the skip-gram model. It is also a 1-hidden-layer neural network. The synthetic training task now uses the average of multiple input context words, rather than a single word as in skip-gram, to predict the center word. Again, the projection weights that turn one-hot words into averageable vectors, of the same width as the hidden layer, are interpreted as the word embeddings. \n",
    "\n",
    "But, Word2Vec doesn't yet get us fixed-size vectors for longer texts.\n",
    "\n",
    "\n",
    "### Paragraph Vector, aka gensim `Doc2Vec`\n",
    "The straightforward approach of averaging each of a text's words' word-vectors creates a quick and crude document-vector that can often be useful. However, Le and Mikolov in 2014 introduced the <i>Paragraph Vector</i>, which usually outperforms such simple-averaging.\n",
    "\n",
    "The basic idea is: act as if a document has another floating word-like vector, which contributes to all training predictions, and is updated like other word-vectors, but we will call it a doc-vector. Gensim's `Doc2Vec` class implements this algorithm. \n",
    "\n",
    "#### Paragraph Vector - Distributed Memory (PV-DM)\n",
    "This is the Paragraph Vector model analogous to Word2Vec CBOW. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a center word based an average of both context word-vectors and the full document's doc-vector.\n",
    "\n",
    "#### Paragraph Vector - Distributed Bag of Words (PV-DBOW)\n",
    "This is the Paragraph Vector model analogous to Word2Vec SG. The doc-vectors are obtained by training a neural network on the synthetic task of predicting a target word just from the full document's doc-vector. (It is also common to combine this with skip-gram testing, using both the doc-vector and nearby word-vectors to predict a single target word, but only one at a time.)\n",
    "\n",
    "### Requirements\n",
    "The following python modules are dependencies for this tutorial:\n",
    "* testfixtures ( `pip install testfixtures` )\n",
    "* statsmodels ( `pip install statsmodels` )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download the IMDB archive if it is not already downloaded (84 MB). This will be our text data for this tutorial.   \n",
    "The data can be found here: http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "This cell will only reattempt steps (such as downloading the compressed data) if their output isn't already present, so it is safe to re-run until it completes successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB archive directory already available without download.\n",
      "Cleaning up dataset...\n",
      " train/pos: 12500 files\n",
      " train/neg: 12500 files\n",
      " test/pos: 12500 files\n",
      " test/neg: 12500 files\n",
      " train/unsup: 50000 files\n",
      "Success, alldata-id.txt is available for next steps.\n",
      "CPU times: user 22.6 s, sys: 11.2 s, total: 33.8 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import locale\n",
    "import glob\n",
    "import os.path\n",
    "import requests\n",
    "import tarfile\n",
    "import sys\n",
    "import codecs\n",
    "from smart_open import smart_open\n",
    "import re\n",
    "\n",
    "dirname = 'aclImdb'\n",
    "filename = 'aclImdb_v1.tar.gz'\n",
    "locale.setlocale(locale.LC_ALL, 'C')\n",
    "all_lines = []\n",
    "\n",
    "if sys.version > '3':\n",
    "    control_chars = [chr(0x85)]\n",
    "else:\n",
    "    control_chars = [unichr(0x85)]\n",
    "\n",
    "# Convert text to lower-case and strip punctuation/symbols from words\n",
    "def normalize_text(text):\n",
    "    norm_text = text.lower()\n",
    "    # Replace breaks with spaces\n",
    "    norm_text = norm_text.replace('<br />', ' ')\n",
    "    # Pad punctuation with spaces on both sides\n",
    "    norm_text = re.sub(r\"([\\.\\\",\\(\\)!\\?;:])\", \" \\\\1 \", norm_text)\n",
    "    return norm_text\n",
    "\n",
    "if not os.path.isfile('aclImdb/alldata-id.txt'):\n",
    "    if not os.path.isdir(dirname):\n",
    "        if not os.path.isfile(filename):\n",
    "            # Download IMDB archive\n",
    "            print(\"Downloading IMDB archive...\")\n",
    "            url = u'http://ai.stanford.edu/~amaas/data/sentiment/' + filename\n",
    "            r = requests.get(url)\n",
    "            with smart_open(filename, 'wb') as f:\n",
    "                f.write(r.content)\n",
    "        # if error here, try `tar xfz aclImdb_v1.tar.gz` outside notebook, then re-run this cell\n",
    "        tar = tarfile.open(filename, mode='r')\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "    else:\n",
    "        print(\"IMDB archive directory already available without download.\")\n",
    "\n",
    "    # Collect & normalize test/train data\n",
    "    print(\"Cleaning up dataset...\")\n",
    "    folders = ['train/pos', 'train/neg', 'test/pos', 'test/neg', 'train/unsup']\n",
    "    for fol in folders:\n",
    "        temp = u''\n",
    "        output = fol.replace('/', '-') + '.txt'\n",
    "        # Is there a better pattern to use?\n",
    "        txt_files = glob.glob(os.path.join(dirname, fol, '*.txt'))\n",
    "        print(\" %s: %i files\" % (fol, len(txt_files)))\n",
    "        with smart_open(os.path.join(dirname, output), \"wb\") as n:\n",
    "            for i, txt in enumerate(txt_files):\n",
    "                with smart_open(txt, \"rb\") as t:\n",
    "                    one_text = t.read().decode(\"utf-8\")\n",
    "                    for c in control_chars:\n",
    "                        one_text = one_text.replace(c, ' ')\n",
    "                    one_text = normalize_text(one_text)\n",
    "                    all_lines.append(one_text)\n",
    "                    n.write(one_text.encode(\"utf-8\"))\n",
    "                    n.write(\"\\n\")\n",
    "\n",
    "    # Save to disk for instant re-use on any future runs\n",
    "    with smart_open(os.path.join(dirname, 'alldata-id.txt'), 'wb') as f:\n",
    "        for idx, line in enumerate(all_lines):\n",
    "            num_line = u\"_*{0} {1}\\n\".format(idx, line)\n",
    "            f.write(num_line.encode(\"utf-8\"))\n",
    "\n",
    "assert os.path.isfile(\"aclImdb/alldata-id.txt\"), \"alldata-id.txt unavailable\"\n",
    "print \"Success, alldata-id.txt is available for next steps.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text data is small enough to be read into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 docs: 25000 train-sentiment, 25000 test-sentiment\n",
      "CPU times: user 7.57 s, sys: 1.27 s, total: 8.84 s\n",
      "Wall time: 8.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "\n",
    "# this data object class suffices as a `TaggedDocument` (with `words` and `tags`) \n",
    "# plus adds other state helpful for our later evaluation/reporting\n",
    "SentimentDocument = namedtuple('SentimentDocument', 'words tags split sentiment')\n",
    "\n",
    "alldocs = []\n",
    "with smart_open('aclImdb/alldata-id.txt', 'rb', encoding='utf-8') as alldata:\n",
    "    for line_no, line in enumerate(alldata):\n",
    "        tokens = gensim.utils.to_unicode(line).split()\n",
    "        words = tokens[1:]\n",
    "        tags = [line_no] # 'tags = [tokens[0]]' would also work at extra memory cost\n",
    "        split = ['train', 'test', 'extra', 'extra'][line_no//25000]  # 25k train, 25k test, 25k extra\n",
    "        sentiment = [1.0, 0.0, 1.0, 0.0, None, None, None, None][line_no//12500] # [12.5K pos, 12.5K neg]*2 then unknown\n",
    "        alldocs.append(SentimentDocument(words, tags, split, sentiment))\n",
    "\n",
    "train_docs = [doc for doc in alldocs if doc.split == 'train']\n",
    "test_docs = [doc for doc in alldocs if doc.split == 'test']\n",
    "\n",
    "print('%d docs: %d train-sentiment, %d test-sentiment' % (len(alldocs), len(train_docs), len(test_docs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the native document-order has similar-sentiment documents in large clumps – which is suboptimal for training – we work with once-shuffled copy of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "doc_list = alldocs[:]  \n",
    "shuffle(doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up Doc2Vec Training & Evaluation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We approximate the experiment of Le & Mikolov [\"Distributed Representations of Sentences and Documents\"](http://cs.stanford.edu/~quocle/paragraph_vector.pdf) with guidance from Mikolov's [example go.sh](https://groups.google.com/d/msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ):\n",
    "\n",
    "`./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1`\n",
    "\n",
    "We vary the following parameter choices:\n",
    "* 100-dimensional vectors, as the 400-d vectors of the paper take a lot of memory and, in our tests of this task, don't seem to offer much benefit\n",
    "* Similarly, frequent word subsampling seems to decrease sentiment-prediction accuracy, so it's left out\n",
    "* `cbow=0` means skip-gram which is equivalent to the paper's 'PV-DBOW' mode, matched in gensim with `dm=0`\n",
    "* Added to that DBOW model are two DM models, one which averages context vectors (`dm_mean`) and one which concatenates them (`dm_concat`, resulting in a much larger, slower, more data-hungry model)\n",
    "* A `min_count=2` saves quite a bit of model memory, discarding only words that appear in a single doc (and are thus no more expressive than the unique-to-each doc vectors themselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t4) vocabulary scanned & state initialized\n",
      "CPU times: user 43.1 s, sys: 675 ms, total: 43.8 s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores, alpha=0.05, comment='alpha=0.05'),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=5, negative=5, hs=0, min_count=2, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "    model.build_vocab(alldocs)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le and Mikolov notes that combining a paragraph vector from Distributed Bag of Words (DBOW) and Distributed Memory (DM) improves performance. We will follow, pairing the models together for evaluation. Here, we concatenate the paragraph vectors obtained from each model with the help of a thin wrapper class included in a gensim test module. (Note that this a separate, later concatenation of output-vectors than the kind of input-window-concatenation enabled by the `dm_concat=1` mode above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "models_by_name['dbow+dmm'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[1]])\n",
    "models_by_name['dbow+dmc'] = ConcatenatedDoc2Vec([simple_models[0], simple_models[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Evaluation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some helper methods for evaluating the performance of our Doc2vec using paragraph vectors. We will classify document sentiments using a logistic regression model based on our paragraph embeddings. We will compare the error rates based on word embeddings from our various Doc2vec models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from random import sample\n",
    "    \n",
    "def logistic_predictor_from_data(train_targets, train_regressors):\n",
    "    \"\"\"Fit a statsmodel logistic predictor on supplied data\"\"\"\n",
    "    logit = sm.Logit(train_targets, train_regressors)\n",
    "    predictor = logit.fit(disp=0)\n",
    "    # print(predictor.summary())\n",
    "    return predictor\n",
    "\n",
    "def error_rate_for_model(test_model, train_set, test_set, \n",
    "                         reinfer_train=False, reinfer_test=False, \n",
    "                         infer_steps=None, infer_alpha=None, infer_subsample=0.2):\n",
    "    \"\"\"Report error rate on test_doc sentiments, using supplied model and train_docs\"\"\"\n",
    "\n",
    "    train_targets = [doc.sentiment for doc in train_set]\n",
    "    if reinfer_train:\n",
    "        train_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in train_set]\n",
    "    else:\n",
    "        train_regressors = [test_model.docvecs[doc.tags[0]] for doc in train_set]\n",
    "    train_regressors = sm.add_constant(train_regressors)\n",
    "    predictor = logistic_predictor_from_data(train_targets, train_regressors)\n",
    "\n",
    "    test_data = test_set\n",
    "    if reinfer_test:\n",
    "        if infer_subsample < 1.0:\n",
    "            test_data = sample(test_data, int(infer_subsample * len(test_data)))\n",
    "        test_regressors = [test_model.infer_vector(doc.words, steps=infer_steps, alpha=infer_alpha) for doc in test_data]\n",
    "    else:\n",
    "        test_regressors = [test_model.docvecs[doc.tags[0]] for doc in test_docs]\n",
    "    test_regressors = sm.add_constant(test_regressors)\n",
    "    \n",
    "    # Predict & evaluate\n",
    "    test_predictions = predictor.predict(test_regressors)\n",
    "    corrects = sum(np.rint(test_predictions) == [doc.sentiment for doc in test_data])\n",
    "    errors = len(test_predictions) - corrects\n",
    "    error_rate = float(errors) / len(test_predictions)\n",
    "    return (error_rate, errors, len(test_predictions), predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk Training & Per-Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that doc-vector training is occurring on *all* documents of the dataset, which includes all TRAIN/TEST/DEV docs.\n",
    "\n",
    "We evaluate each model's sentiment predictive power based on error rate, and the evaluation is done for each model. \n",
    "\n",
    "(On a 4-core 2.6Ghz Intel Core i7, these 20 passes training and evaluating 3 main models takes about an hour.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "error_rates = defaultdict(lambda: 1.0)  # To selectively print only best errors achieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "CPU times: user 19min 33s, sys: 2min 16s, total: 21min 50s\n",
      "Wall time: 8min 54s\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "CPU times: user 1.78 s, sys: 153 ms, total: 1.93 s\n",
      "Wall time: 631 ms\n",
      "\n",
      "0.102560 Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "CPU times: user 28min 25s, sys: 2min 24s, total: 30min 50s\n",
      "Wall time: 10min 41s\n",
      "\n",
      "Evaluating Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "CPU times: user 1.57 s, sys: 154 ms, total: 1.73 s\n",
      "Wall time: 560 ms\n",
      "\n",
      "0.154360 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "Training Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "CPU times: user 1h 3min 1s, sys: 1min 5s, total: 1h 4min 6s\n",
      "Wall time: 17min 25s\n",
      "\n",
      "Evaluating Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "CPU times: user 1.9 s, sys: 135 ms, total: 2.04 s\n",
      "Wall time: 657 ms\n",
      "\n",
      "0.222920 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in simple_models: \n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(doc_list, total_examples=len(doc_list), epochs=model.epochs)\n",
    "    \n",
    "    print(\"\\nEvaluating %s\" % model)\n",
    "    %time err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "CPU times: user 4.18 s, sys: 375 ms, total: 4.55 s\n",
      "Wall time: 1.58 s\n",
      "\n",
      "0.101440 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "CPU times: user 4.2 s, sys: 370 ms, total: 4.57 s\n",
      "Wall time: 1.45 s\n",
      "\n",
      "0.104520 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]: \n",
    "    print(\"\\nEvaluating %s\" % model)\n",
    "    %time err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs)\n",
    "    error_rates[str(model)] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Achieved Sentiment-Prediction Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err_rate Model\n",
      "0.101440 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "0.102560 Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "0.104520 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "0.154360 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "0.222920 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "# Compare error rates achieved, best-to-worst\n",
    "print(\"Err_rate Model\")\n",
    "for rate, name in sorted((rate, name) for name, rate in error_rates.items()):\n",
    "    print(\"%f %s\" % (rate, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our testing, contrary to the results of the paper, on this problem, PV-DBOW alone performs as good as anything else. Concatenating vectors from different models only offers a tiny predictive improvement – and stays generally close to the best-performing solo model included. \n",
    "\n",
    "The best results achieved here are just around 10% error rate, still a long way from the paper's reported 7.42% error rate. \n",
    "\n",
    "(Other trials not shown, with larger vectors and other changes, also don't come close to the paper's reported value. Others around the net have reported a similar inability to reproduce the paper's best numbers. The PV-DM/C mode improves a bit with many more training epochs – but doesn't reach parity with PV-DBOW.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are inferred vectors close to the precalculated ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for doc 95761...\n",
      "Doc2Vec(dbow,d100,n5,mc2,t4):\n",
      " [(95761, 0.9792555570602417), (88832, 0.5553798079490662), (92464, 0.5484659671783447)]\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4):\n",
      " [(95761, 0.8996705412864685), (43225, 0.5820556879043579), (79338, 0.5665184259414673)]\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t4):\n",
      " [(95761, 0.8924344778060913), (18832, 0.45134425163269043), (18517, 0.44292938709259033)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neuscratch/Dev/gensim/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # Pick random doc; re-run cell for more examples\n",
    "print('for doc %d...' % doc_id)\n",
    "for model in simple_models:\n",
    "    inferred_docvec = model.infer_vector(alldocs[doc_id].words)\n",
    "    print('%s:\\n %s' % (model, model.docvecs.most_similar([inferred_docvec], topn=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Yes, here the stored vector from 20 epochs of training is usually one of the closest to a freshly-inferred vector for the same words. Defaults for inference may benefit from tuning for each dataset or model parameters.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do close documents seem more related than distant ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (27777): «this was a great film in every sense of the word . it tackles the subject of tribadism in a society that is quite intolerant of any deviations from the norm . it criticises a great many indian customs that many find oppressive -- such as the arranging of marriages by others , the importance of status and face , religious hypocrisy , sexism , the valuation of women in terms of their baby-making capacity , the binding concepts of duty and so on . at the heart of the film is a touching love story that goes beyond such limitations of the society which the two protagonists find themselves . the film is well-acted and genuine , completely believable from beginning to end , unlike most bollywood flicks . the main faults of the film as i saw it was first , that the two lovers seem drawn to one another not necessarily by a natural affinity for each other as much as the fact that they are stuck in dead-end marriages with no passion and no rewards . this may play a part in the sexual awakening of the characters , but most people stuck in the same situation will not \" turn homosexual \" . it seems clear from the beginning of the film that the two characters are quite heterosexual -- when radha does her scene at the end of the movie with aashok , she makes it quite clear that \" without desire she was dead \" , and the implication was that if he had desired so , he could have fulfilled her quite completely , and also when sita seemed very disappointed when her husband seemed to not like her . such situations do not turn people into homosexuals -- they may seek comfort in others in the same position , but inthe film it is not at all made clear that they are lesbians from the beginning -- quite the opposite . some people are bisexual , it is true , but most tend to be either hetero- or homosexual . in the case of the ladies in the film , both had insensitive jerks for husbands . . . if this had not been the case , would they have naturally found the need to express their desire in a relationship that they may have otherwise not have considered ? the film ignores this . the other fault is the naming of the characters . . . the names sita and radha seem contrived deliberately to shock and outrage ( imagine a film in america depicting a gay relationship between a man named \" jesus \" and another named \" paul \" ! ) by using names associated with various hindoo scriptures . the film is strong enough to stand on its own and needs no such devices in my opinion . at any rate , the faults do not take much away from the power of the movie . it is indeed a very touching and powerful story -- the images and characters will stay with you a long time after you leave the theatre .»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/c,d100,n5,w5,mc2,t4):\n",
      "\n",
      "MOST (10050, 0.5033408999443054): «\" ruby in paradise \" is a beautiful , coming-of-age story about a young woman , ruby lee gissing , escaping her stifling roots to become herself . although the title character is played artfully by the gorgeous ashley judd -- in likely her first movie role , albeit one to be quite proud of -- the emphasis is not upon becoming \" somebody , \" a la the next madonna ( whether jesus' mother or the lurid , attention-hungry singer ) . it instead emphasizes following ones' instincts and being somewhat introspective about them , to grow into one's ideal , adult self . note : this isn't an action movie ! ! ! it uses an occasional voice-over narration ( by ms . judd ) while writing in her journal -- and oh , i see i've just lost the male half of the readers out there . but be patient with this beautiful movie , where we learn that one's bliss can be discovered in -- oh , i dunno , carrying water and chopping wood . actor/director/writer todd field , who played nick nightingale in \" eyes wide shut , \" co-stars as ruby lee's noble love interest , one who helps her heal her idea of relationships implanted from youth . but not even his character is the answer for ruby lee : there's no external hero imposed upon her . the ultimate message is that we are responsible for ourselves . writer/director victor nunez , who also wrote/directed \" ulee's gold , \" did an amazing job showing a young woman growing into herself -- confronting age-old challenges of good v . evil along the way . the supporting cast is also stellar , and the music used , particularly the cuts by chanteuse sam phillips ( whom i hear is the wife of t . bone burnett ) , is right on -- most especially \" trying to hold on to the earth . \" now , when i hear the first few chords of that song , tears spring to my eyes , pavlovian and unbidden -- not sure if it's the music , or the indelible connection to the movie's quiet , charming message of empowerment . this movie is highly recommended for any young person trying to find his/her way . for any woman of any age , it is a must see ! the downside : it is not on dvd , except in spanish . ( we learned , however , that it is legal to make one copy of a vhs version , which can be readily found online . my beloved husband found someone with a vhs copy and got a dvd copy made for me . ) although this treasure of a movie occasionally pops up on-air  on an indie channel , usually  you can't count on that when you might need it most as a tonic to soothe the pressures of the world . so buy a copy for yourself . this movie should have a major re-release , and it would , if i were queen of hollywood . -- figgy jones»\n",
      "\n",
      "MEDIAN (15208, -0.0026090294122695923): «beating the bad guys . . . again is the tag line for this movie , it exposes so much truth about it . home alone one and two , film classics . home alone three and four , a good film if you're three ! like sharkboy and lavagirl , as hard as it tries to be funny , it's not . culkin is replaced by alex d'linz or something else . he's a very bland actor with bland performances , but it's not entirely his fault , the writing called for bland vocabulary and bland expressions . the pranks are just copied from the first two with different crooks , and you'd have to be blind to think those chicken pox are real . a good choice if you are a preschool teacher in which is showing this film on a rainy day . and to make things worst , a totally different cast , go see if you don't believe me , but you'll regret it .»\n",
      "\n",
      "LEAST (44943, -0.4170834422111511): «the comic strip featured actors from 'the young one's' - a student based sitcom from the 80's . comic strip features included parodies of westerns , 'the famous 5' , and the professionals - all a lot funnier than this . having said that alexei sayle puts in a good turn as a traffic cop with ambition and the soundtrack features great music from the era . 5/10»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "doc_id = np.random.randint(simple_models[0].docvecs.count)  # pick random doc, re-run cell for more examples\n",
    "model = random.choice(simple_models)  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%d): «%s»\\n' % (doc_id, ' '.join(alldocs[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(alldocs[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat, in terms of reviewer tone, movie genre, etc... the MOST cosine-similar docs usually seem more like the TARGET than the MEDIAN or LEAST... especially if the MOST has a cosine-similarity > 0.5. Re-run the cell to try another random target document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the word vectors show useful similarities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_models = simple_models[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar words for 'florida' (335 occurences)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Doc2Vec(dbow,d100,n5,mc2,t4)</th><th>Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)</th><th>Doc2Vec(dm/c,d100,n5,w5,mc2,t4)</th></tr><tr><td>[(u'frajko', 0.41190698742866516),<br>\n",
       "(u'salt-water', 0.40267983078956604),<br>\n",
       "(u'abhor', 0.38860034942626953),<br>\n",
       "(u'laverty', 0.3803873062133789),<br>\n",
       "(u'zeena', 0.373787522315979),<br>\n",
       "(u'short-circuited', 0.3734702169895172),<br>\n",
       "(u\"perkins's\", 0.36940163373947144),<br>\n",
       "(u'charater', 0.36900147795677185),<br>\n",
       "(u'sountrack', 0.36797666549682617),<br>\n",
       "(u\"relief'\", 0.36683017015457153),<br>\n",
       "(u'gorky', 0.36592555046081543),<br>\n",
       "(u'lefty', 0.35914239287376404),<br>\n",
       "(u'chauffeurs', 0.35870635509490967),<br>\n",
       "(u'over-acted', 0.35760819911956787),<br>\n",
       "(u'songwriter', 0.35664206743240356),<br>\n",
       "(u'oppressors', 0.35491055250167847),<br>\n",
       "(u'resuscitated', 0.3537188768386841),<br>\n",
       "(u'griswold', 0.3514401316642761),<br>\n",
       "(u'earing', 0.35099783539772034),<br>\n",
       "(u'*bad*', 0.3504103422164917)]</td><td>[(u'california', 0.7730273008346558),<br>\n",
       "(u'mexico', 0.769424319267273),<br>\n",
       "(u'chicago', 0.7522618174552917),<br>\n",
       "(u'london', 0.7519516944885254),<br>\n",
       "(u'france', 0.750676691532135),<br>\n",
       "(u'wisconsin', 0.7419590950012207),<br>\n",
       "(u'australia', 0.7416296005249023),<br>\n",
       "(u'alaska', 0.738996148109436),<br>\n",
       "(u'india', 0.7347420454025269),<br>\n",
       "(u'africa', 0.730577826499939),<br>\n",
       "(u'europe', 0.7210973501205444),<br>\n",
       "(u'canada', 0.7049627304077148),<br>\n",
       "(u'vermont', 0.6993812918663025),<br>\n",
       "(u'england', 0.698597252368927),<br>\n",
       "(u'utah', 0.6982070803642273),<br>\n",
       "(u'oregon', 0.6964374780654907),<br>\n",
       "(u'italy', 0.6952856779098511),<br>\n",
       "(u'america', 0.6915072202682495),<br>\n",
       "(u'spain', 0.686146080493927),<br>\n",
       "(u'portland', 0.6788756251335144)]</td><td>[(u'california', 0.7078369855880737),<br>\n",
       "(u'boston', 0.7032774686813354),<br>\n",
       "(u'italy', 0.6966679096221924),<br>\n",
       "(u'ireland', 0.6952470541000366),<br>\n",
       "(u'paris', 0.6877654790878296),<br>\n",
       "(u'louisiana', 0.6768959760665894),<br>\n",
       "(u'london', 0.6698304414749146),<br>\n",
       "(u'wyoming', 0.6552854180335999),<br>\n",
       "(u'switzerland', 0.6498767733573914),<br>\n",
       "(u'oregon', 0.6481806039810181),<br>\n",
       "(u'wales', 0.6445456147193909),<br>\n",
       "(u'ny', 0.644187331199646),<br>\n",
       "(u'korea', 0.6440141201019287),<br>\n",
       "(u'greece', 0.6436896324157715),<br>\n",
       "(u'norway', 0.642290472984314),<br>\n",
       "(u'england', 0.641778290271759),<br>\n",
       "(u'africa', 0.6393018364906311),<br>\n",
       "(u'spain', 0.6388403177261353),<br>\n",
       "(u'berlin', 0.632797360420227),<br>\n",
       "(u'india', 0.632185697555542)]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from IPython.display import HTML\n",
    "# pick a random word with a suitable number of occurences\n",
    "while True:\n",
    "    word = random.choice(word_models[0].wv.index2word)\n",
    "    if word_models[0].wv.vocab[word].count > 10:\n",
    "        break\n",
    "# or uncomment below line, to just pick a word from the relevant domain:\n",
    "#word = 'comedy/drama'\n",
    "similars_per_model = [str(model.wv.most_similar(word, topn=20)).replace('), ','),<br>\\n') for model in word_models]\n",
    "similar_table = (\"<table><tr><th>\" +\n",
    "    \"</th><th>\".join([str(model) for model in word_models]) + \n",
    "    \"</th></tr><tr><td>\" +\n",
    "    \"</td><td>\".join(similars_per_model) +\n",
    "    \"</td></tr></table>\")\n",
    "print(\"most similar words for '%s' (%d occurences)\" % (word, simple_models[0].wv.vocab[word].count))\n",
    "HTML(similar_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the DBOW words look meaningless? That's because the gensim DBOW model doesn't train word vectors – they remain at their random initialized values – unless you ask with the `dbow_words=1` initialization parameter. Concurrent word-training slows DBOW mode significantly, and offers little improvement (and sometimes a little worsening) of the error rate on this IMDB sentiment-prediction task, but may be appropriate on other tasks, or if you also need word-vectors. \n",
    "\n",
    "Words from DM models tend to show meaningfully similar words when there are many examples in the training data (as with 'plot' or 'actor'). (All DM modes inherently involve word-vector training concurrent with doc-vector training.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the word vectors from this dataset any good at analogies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success, questions-words.txt is available for next steps.\n"
     ]
    }
   ],
   "source": [
    "# grab the file if not already local\n",
    "questions_filename = 'questions-words.txt'\n",
    "if not os.path.isfile(questions_filename):\n",
    "    # Download IMDB archive\n",
    "    print(\"Downloading analogy questions file...\")\n",
    "    url = u'https://raw.githubusercontent.com/tmikolov/word2vec/master/questions-words.txt'\n",
    "    r = requests.get(url)\n",
    "    with smart_open(questions_filename, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "assert os.path.isfile(questions_filename), \"questions-words.txt unavailable\"\n",
    "print \"Success, questions-words.txt is available for next steps.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc2,t4): 0.00% correct (0 of 14657)\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4): 17.28% correct (2532 of 14657)\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc2,t4): 18.81% correct (2757 of 14657)\n"
     ]
    }
   ],
   "source": [
    "# Note: this analysis takes many minutes\n",
    "for model in word_models:\n",
    "    score, sections = model.wv.evaluate_word_analogies('questions-words.txt')\n",
    "    correct, incorrect = len(sections[-1]['correct']), len(sections[-1]['incorrect'])\n",
    "    print('%s: %0.2f%% correct (%d of %d)' % (model, float(correct*100)/(correct+incorrect), correct, correct+incorrect))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though this is a tiny, domain-specific dataset, it shows some meager capability on the general word analogies – at least for the DM/concat and DM/mean models which actually train word vectors. (The untrained random-initialized words of the DBOW model of course fail miserably.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This cell left intentionally erroneous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced technique: re-inferring doc-vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the bulk-trained vectors had much of their training early, when the model itself was still settling, it is *sometimes* the case that rather than using the bulk-trained vectors, new vectors re-inferred from the final state of the model serve better as the input/test data for downstream tasks. \n",
    "\n",
    "Our `error_rate_for_model()` function already had a non-default option to re-infer vectors before training/testing the classifier, so here we test that option. (This takes as long or longer than initial bulk training, as inference is only single-threaded.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4) re-inferred\n",
      "CPU times: user 6min 42s, sys: 888 ms, total: 6min 43s\n",
      "Wall time: 6min 42s\n",
      "\n",
      "0.104520 Doc2Vec(dbow,d100,n5,mc2,t4)_reinferred\n",
      "\n",
      "Evaluating Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4) re-inferred\n",
      "CPU times: user 8min 37s, sys: 1.21 s, total: 8min 38s\n",
      "Wall time: 8min 36s\n",
      "\n",
      "0.145280 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)_reinferred\n",
      "\n",
      "Evaluating Doc2Vec(dm/c,d100,n5,w5,mc2,t4) re-inferred\n",
      "CPU times: user 15min 39s, sys: 1.28 s, total: 15min 41s\n",
      "Wall time: 15min 39s\n",
      "\n",
      "0.211520 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)_reinferred\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4) re-inferred\n",
      "CPU times: user 15min 35s, sys: 1.63 s, total: 15min 37s\n",
      "Wall time: 15min 34s\n",
      "\n",
      "0.102360 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)_reinferred\n",
      "\n",
      "Evaluating Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4) re-inferred\n",
      "CPU times: user 22min 29s, sys: 1.76 s, total: 22min 31s\n",
      "Wall time: 22min 28s\n",
      "\n",
      "0.105920 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)_reinferred\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in simple_models + [models_by_name['dbow+dmm'], models_by_name['dbow+dmc']]: \n",
    "    print(\"Evaluating %s re-inferred\" % str(model))\n",
    "    pseudomodel_name = str(model)+\"_reinferred\"\n",
    "    %time err_rate, err_count, test_count, predictor = error_rate_for_model(model, train_docs, test_docs, reinfer_train=True, reinfer_test=True, infer_subsample=1.0)\n",
    "    error_rates[pseudomodel_name] = err_rate\n",
    "    print(\"\\n%f %s\\n\" % (err_rate, pseudomodel_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err_rate Model\n",
      "0.101440 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "0.102360 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)_reinferred\n",
      "0.102560 Doc2Vec(dbow,d100,n5,mc2,t4)\n",
      "0.104520 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n",
      "0.104520 Doc2Vec(dbow,d100,n5,mc2,t4)_reinferred\n",
      "0.105920 Doc2Vec(dbow,d100,n5,mc2,t4)+Doc2Vec(dm/c,d100,n5,w5,mc2,t4)_reinferred\n",
      "0.145280 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)_reinferred\n",
      "0.154360 Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc2,t4)\n",
      "0.211520 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)_reinferred\n",
      "0.222920 Doc2Vec(dm/c,d100,n5,w5,mc2,t4)\n"
     ]
    }
   ],
   "source": [
    "# Compare error rates achieved, best-to-worst\n",
    "print(\"Err_rate Model\")\n",
    "for rate, name in sorted((rate, name) for name, rate in error_rates.items()):\n",
    "    print(\"%f %s\" % (rate, name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we do *not* see much benefit of re-inference. It's more likely to help if the initial training used fewer epochs (10 is also a common value in the literature for larger datasets), or perhaps in larger datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get copious logging output from above steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "rootLogger = logging.getLogger()\n",
    "rootLogger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To auto-reload python code while developing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
